{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro:\n",
    "This notebook was authored to help demonstrate the brittleness of NSFW classifiers in the face of OOD images far away from the learnt manifold.\n",
    "\n",
    "Specifically we focus on the false positive case that caught the media attention from here:\n",
    "https://www.facebook.com/TheSeedCompanyNL/posts/2685298268399733?comment_id=2687752171487676&notif_id=1602199524375052&notif_t=feedback_reaction_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle# For the bounding box\n",
    "from scipy.stats import describe\n",
    "import itertools\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.image import random_crop\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSFW score model import\n",
    "\n",
    "We use the 5-class NSFW classifier model (https://github.com/GantMan/nsfw_model).\n",
    "The 5-classes are:\n",
    "- drawings - safe for work drawings (including anime)\n",
    "- hentai - hentai and pornographic drawings\n",
    "- neutral - safe for work neutral images\n",
    "- porn - pornographic images, sexual acts\n",
    "- sexy - sexually explicit images, not pornography\n",
    "\n",
    "\n",
    "\n",
    "Let us begin with the image from https://www.bbc.com/news/54467384\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsfw_detector import predict\n",
    "model_path=os.path.join(nsfw_dir,'nsfw_mobilenet2.224x224.h5')\n",
    "model=predict.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_image=os.getcwd()+'/fb_onions.png'\n",
    "img = image.load_img(trial_image, target_size=(224, 224))\n",
    "X=predict.classify(model,trial_image)\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.barh(np.arange(5),X[trial_image].values())\n",
    "plt.yticks(np.arange(5),list(X[trial_image].keys()))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment-1: Does this happen 'in the wild'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for im in os.listdir('./Onions'):\n",
    "    trial_image='./Onions/'+im\n",
    "    img = image.load_img(trial_image, target_size=(224, 224))\n",
    "    X=predict.classify(model,trial_image)\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.barh(np.arange(5),X[trial_image].values())\n",
    "    plt.yticks(np.arange(5),list(X[trial_image].keys()))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment -2: Random crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_array=np.array(PIL.Image.open('./Onions/fb_onions.png'))\n",
    "# Let us create 32 random crops \n",
    "for ind in tqdm(range(32)):\n",
    "    \n",
    "    im_crop=random_crop(im_array,[224,224,3])\n",
    "    im = Image.fromarray(im_crop.numpy())\n",
    "    trial_image=f'./onions_crop/outfile_{ind}.jpg'\n",
    "    im.save(trial_image)\n",
    "    X=predict.classify(model,trial_image)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(im_crop)\n",
    "    plt.subplot(122)\n",
    "    plt.barh(np.arange(5),X[trial_image].values())\n",
    "    plt.yticks(np.arange(5),list(X[trial_image].keys()))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./onion_gif/onion_{ind}.png',dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the results to a gif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir('./onion_gif')\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread('./onion_gif/'+file_name))\n",
    "import imageio\n",
    "imageio.mimwrite('onions.gif', image_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
